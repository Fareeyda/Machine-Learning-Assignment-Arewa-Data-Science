{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation and sentiment analysis with ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation is a very hard problem compounded by the fact that there are thousands of languages and each can have very different grammar rules. One approach is to convert the formal grammar rules for one language, such as English, into a non-language dependent structure, and then translate it by converting back to another language. This approach means that you would take the following steps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    1 Identification. Identify or tag the words in input language into nouns, verbs etc.\n",
    "    \n",
    "    2 Create translation. Produce a direct translation of each word in the target language format.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentence, English to Irish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 'English', the sentence I feel happy is three words in the order:\n",
    "\n",
    "    subject (I)\n",
    "\n",
    "    verb (feel)\n",
    "\n",
    "    adjective (happy)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in the 'Irish' language, the same sentence has a very different grammatical structure - emotions like \"happy\" or \"sad\" are expressed as being upon you."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The English phrase I feel happy in Irish would be Tá athas orm. A literal translation would be Happy is upon me."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Irish speaker translating to English would say I feel happy, not Happy is upon me, because they understand the meaning of the sentence, even if the words and sentence structure are different."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formal order for the sentence in Irish are:\n",
    "\n",
    "    verb (Tá or is)\n",
    "\n",
    "    adjective (athas, or happy)\n",
    "    \n",
    "    subject (orm, or upon me)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive translation program might translate words only, ignoring the sentence structure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've learned a second (or third or more) language as an adult, you might have started by thinking in your native language, translating a concept word by word in your head to the second language, and then speaking out your translation. This is similar to what naive translation computer programs are doing. It's important to get past this phase to attain fluency!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive translation leads to bad (and sometimes hilarious) mistranslations: I feel happy translates literally to Mise bhraitheann athas in Irish. That means (literally) me feel happy and is not a valid Irish sentence. Even though English and Irish are languages spoken on two closely neighboring islands, they are very different languages with different grammar structures."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned about the formal rules approach to natural language processing. Another approach is to ignore the meaning of the words, and instead use machine learning to detect patterns. This can work in translation if you have lots of text (a corpus) or texts (corpora) in both the origin and target languages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, consider the case of Pride and Prejudice, a well-known English novel written by Jane Austen in 1813. If you consult the book in English and a human translation of the book in French, you could detect phrases in one that are idiomatically translated into the other. You'll do that in a minute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, when an English phrase such as I have no money is translated literally to French, it might become Je n'ai pas de monnaie. \"Monnaie\" is a tricky french 'false cognate', as 'money' and 'monnaie' are not synonymous. A better translation that a human might make would be Je n'ai pas d'argent, because it better conveys the meaning that you have no money (rather than 'loose change' which is the meaning of 'monnaie')."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an ML model has enough human translations to build a model on, it can improve the accuracy of translations by identifying common patterns in texts that have been previously translated by expert human speakers of both languages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use TextBlob to translate sentences. Try the famous first line of Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnp_extractors\u001b[39;00m \u001b[39mimport\u001b[39;00m ConllExtractor\n\u001b[0;32m      5\u001b[0m blob \u001b[39m=\u001b[39m TextBlob(\n\u001b[0;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mIt is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(blob\u001b[39m.\u001b[39;49mtranslate(to\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfr\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\Arewads\\lib\\site-packages\\textblob\\blob.py:568\u001b[0m, in \u001b[0;36mBaseBlob.translate\u001b[1;34m(self, from_lang, to)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Translate the blob to another language.\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mUses the Google Translate API. Returns a new TextBlob.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39m:rtype: :class:`BaseBlob <BaseBlob>`\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    564\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTextBlob.translate is deprecated and will be removed in a future release. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    565\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mUse the official Google Translate API instead.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    566\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m\n\u001b[0;32m    567\u001b[0m )\n\u001b[1;32m--> 568\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranslator\u001b[39m.\u001b[39;49mtranslate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw,\n\u001b[0;32m    569\u001b[0m                       from_lang\u001b[39m=\u001b[39;49mfrom_lang, to_lang\u001b[39m=\u001b[39;49mto))\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\Arewads\\lib\\site-packages\\textblob\\translate.py:61\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_translation(source, result)\n\u001b[0;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\Arewads\\lib\\site-packages\\textblob\\translate.py:88\u001b[0m, in \u001b[0;36mTranslator._validate_translation\u001b[1;34m(self, source, result)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m PY2:\n\u001b[0;32m     87\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39;49mstrip() \u001b[39m==\u001b[39m source\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m NotTranslated(\u001b[39m'\u001b[39m\u001b[39mTranslation API returned the input string unchanged.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "\n",
    "\n",
    "blob = TextBlob(\n",
    "    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife!\"\n",
    ")\n",
    "print(blob.translate(to=\"fr\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob does a pretty good job at the translation: \"C'est une vérité universellement reconnue, qu'un homme célibataire en possession d'une bonne fortune doit avoir besoin d'une femme!\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be argued that TextBlob's translation is far more exact, in fact, than the 1932 French translation of the book by V. Leconte and Ch. Pressoir:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another area where machine learning can work very well is sentiment analysis. A non-ML approach to sentiment is to identify words and phrases which are 'positive' and 'negative'. Then, given a new piece of text, calculate the total value of the positive, negative and neutral words to identify the overall sentiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is easily tricked as you may have seen in the Marvin task - the sentence Great, that was a wonderful waste of time, I'm glad we are lost on this dark road is a sarcastic, negative sentiment sentence, but the simple algorithm detects 'great', 'wonderful', 'glad' as positive and 'waste', 'lost' and 'dark' as negative. The overall sentiment is swayed by these conflicting words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop a second and think about how we convey sarcasm as human speakers. Tone inflection plays a large role. Try to say the phrase \"Well, that film was awesome\" in different ways to discover how your voice conveys meaning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML approach would be to manually gather negative and positive bodies of text - tweets, or movie reviews, or anything where the human has given a score and a written opinion. Then NLP techniques can be applied to opinions and scores, so that patterns emerge (e.g., positive movie reviews tend to have the phrase 'Oscar worthy' more than negative movie reviews, or positive restaurant reviews say 'gourmet' much more than 'disgusting')."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - sentimental sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment is measured in with a polarity of -1 to 1, meaning -1 is the most negative sentiment, and 1 is the most positive. Sentiment is also measured with an 0 - 1 score for objectivity (0) and subjectivity (1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look at Jane Austen's Pride and Prejudice. The text is available here at Project Gutenberg. The sample below shows a short program which analyses the sentiment of first and last sentences from the book and display its sentiment polarity and subjectivity/objectivity score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should use the TextBlob library (described above) to determine sentiment (you do not have to write your own sentiment calculator) in the following task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. has a sentiment of Sentiment(polarity=0.20952380952380953, subjectivity=0.27142857142857146)\n",
      "Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them. has a sentiment of Sentiment(polarity=0.7, subjectivity=0.8)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "quote1 = \"\"\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\"\"\n",
    "\n",
    "quote2 = \"\"\"Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them.\"\"\"\n",
    "\n",
    "sentiment1 = TextBlob(quote1).sentiment\n",
    "sentiment2 = TextBlob(quote2).sentiment\n",
    "\n",
    "print(quote1 + \" has a sentiment of \" + str(sentiment1))\n",
    "print(quote2 + \" has a sentiment of \" + str(sentiment2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Remove the metadata from the book\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m text \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpge1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mtext\n\u001b[0;32m     13\u001b[0m \u001b[39m# Create a TextBlob object\u001b[39;00m\n\u001b[0;32m     14\u001b[0m blob \u001b[39m=\u001b[39m TextBlob(text)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download the book from Project Gutenberg\n",
    "url = \"# downloading using Python: Yay\n",
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/42671/42671.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Get the filename from the URL\n",
    "    filename = 'pride_and_prejudice.txt'\n",
    "\n",
    "    # Save the file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Remove the metadata from the book\n",
    "text = soup.find(\"div\", id=\"pge1\").text\n",
    "\n",
    "# Create a TextBlob object\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Analyze each sentence in the book\n",
    "sentences = blob.sentences\n",
    "positive_sentences = []\n",
    "negative_sentences = []\n",
    "for sentence in sentences:\n",
    "  polarity = sentence.sentiment.polarity\n",
    "  if polarity == 1:\n",
    "    positive_sentences.append(sentence)\n",
    "  elif polarity == -1:\n",
    "    negative_sentences.append(sentence)\n",
    "\n",
    "# Print out the positive and negative sentences\n",
    "print(\"Positive sentences:\")\n",
    "for sentence in positive_sentences:\n",
    "  print(sentence)\n",
    "\n",
    "print(\"Negative sentences:\")\n",
    "for sentence in negative_sentences:\n",
    "  print(sentence)\n",
    "\n",
    "# Print out the number of positive and negative sentences\n",
    "print(\"Number of positive sentences:\", len(positive_sentences))\n",
    "print(\"Number of negative sentences:\", len(negative_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pride-and-prejudice.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlob\n\u001b[0;32m      5\u001b[0m \u001b[39m# Download a copy of Pride and Prejudice from Project Gutenberg as a .txt file.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Remove the metadata at the start and end of the file, leaving only the original text.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mpride-and-prejudice.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m   text \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m**\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m***\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Create a TextBlob using the book string.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\Arewads\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pride-and-prejudice.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# Download a copy of Pride and Prejudice from Project Gutenberg as a .txt file.\n",
    "# Remove the metadata at the start and end of the file, leaving only the original text.\n",
    "with open(\"pride-and-prejudice.txt\", \"r\") as f:\n",
    "  text = f.read().replace(\"**\", \"\").replace(\"***\", \"\")\n",
    "\n",
    "# Create a TextBlob using the book string.\n",
    "blob = textblob.TextBlob(text)\n",
    "\n",
    "# Analyze each sentence in the book in a loop.\n",
    "positive_sentences = []\n",
    "negative_sentences = []\n",
    "for sentence in blob.sentences:\n",
    "  polarity = sentence.sentiment.polarity\n",
    "  if polarity == 1:\n",
    "    positive_sentences.append(sentence)\n",
    "  elif polarity == -1:\n",
    "    negative_sentences.append(sentence)\n",
    "\n",
    "# Print out all the positive sentences and negative sentences (separately) and the number of each.\n",
    "print(\"Positive sentences:\")\n",
    "for sentence in positive_sentences:\n",
    "  print(sentence)\n",
    "print(\"Number of positive sentences:\", len(positive_sentences))\n",
    "\n",
    "print(\"Negative sentences:\")\n",
    "for sentence in negative_sentences:\n",
    "  print(sentence)\n",
    "print(\"Number of negative sentences:\", len(negative_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     content \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m \u001b[39m# making textblob of the    \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m book \u001b[39m=\u001b[39m TextBlob(content)\n\u001b[0;32m      7\u001b[0m \u001b[39m# initializing the containers for the sentences\u001b[39;00m\n\u001b[0;32m      8\u001b[0m positive_sentiments \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# opening the file\n",
    "import nltk\n",
    "with open('pride_and_prejudice.txt',encoding=\"utf8\") as f:\n",
    "    content = f.read()\n",
    "# making textblob of the    \n",
    "book = TextBlob(content)\n",
    "# initializing the containers for the sentences\n",
    "positive_sentiments = []\n",
    "negative_sentiments = []\n",
    "\n",
    "# assigning sentences based on extremes in polarity\n",
    "for sentence in book.sentences:\n",
    "    if sentence.sentiment.polarity == 1:\n",
    "        positive_sentiments.append(sentence)\n",
    "    if sentence.sentiment.polarity == -1:\n",
    "        negative_sentiments.append(sentence)\n",
    "\n",
    "# finally printing the sentences\n",
    "print('The ' + str(len(positive_sentiments)) + ' most positive sentences: ')\n",
    "for sentence in positive_sentiments:\n",
    "    print('+ ' + str(sentence.replace('\\n', '').replace('      ', ' ')))\n",
    "    \n",
    "print('The ' + str(len(negative_sentiments)) + ' most negative sentences: ')\n",
    "for sentence in negative_sentiments:\n",
    "    print('- ' + str(sentence.replace('\\n', '').replace('      ', ' ')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arewads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
