{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the solvers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson you learned about the various solvers that pair algorithms with a machine learning process to create an accurate model. Walk through the solvers listed in the lesson and pick two. In your own words, compare and contrast these two solvers. What kind of problem do they address? How do they work with various data structures? Why would you pick one over another?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAGA SOLVER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAGA (Stochastic Average Gradient Descent) is an optimization algorithm used in machine learning. It is a variant of the SAG algorithm and is used for solving large-scale optimization problems. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regularizer .\n",
    "\n",
    "SAGA is particularly useful for sparse multinomial logistic regression and supports non-smooth penalty L1 option (i.e. L1 Regularization). It can handle both dense and sparse input. It is a solver of choice for sparse multinomial logistic regression and has better theoretical convergence compared to SAG ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEWTON-CG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton-CG (Newton-Conjugate Gradient) is an optimization algorithm used in machine learning. It is an iterative algorithm based on Newtonâ€™s method and the linear conjugate gradient algorithm. Newton-CG is used for solving large-scale optimization problems and can handle both dense and sparse input.\n",
    "\n",
    "Newton-CG uses a quadratic approximation of the objective function and takes into account both first and second partial derivatives . It can be used for minimizing smooth nonconvex objective functions . In scikit-learn, Newton-CG is one of the solvers that can be used for logistic regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHY I WOULD PICK SAGA OVER NEWTON-CG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAGA may be a better choice for sparse multinomial logistic regression with L1 regularization,\n",
    "\n",
    " while Newton-CG may be a better choice for minimizing smooth nonconvex objective functions.\n",
    " \n",
    " it all depends on your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arewads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
